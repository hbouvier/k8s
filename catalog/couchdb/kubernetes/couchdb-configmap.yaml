kind: ConfigMap
apiVersion: v1
metadata:
  name: couchdb
  labels:
    app: couchdb
    component: couchdb
    role: member
    release: stable      # canary
    environment: staging # dev, qa, production
    tier: database       # frontend, backend, cache
    partition: all       # customer_1, customer_2, developer_1, beta_release
data:
  # Erlang VM settings. The -name flag activates the Erlang distribution; there
  # should be no reason to change this setting. The -setcookie flag is used to
  # control the Erlang magic cookie. CouchDB cluster nodes can only establish a
  # connection with one another if they share the same magic cookie.
  erlflags: >
    -name couchdb
    -setcookie F2D6862C-8236-4DF9-B013-9FEDAA017972
  # CouchDB server setttings. The UUID is employed in replication checkpoints
  # and should be for unique for each cluster, but shared by all members of a
  # cluster.
  kubernetes.ini: |
    # Each Couchdb Cluster MUST have a unique uuid per Cluster
    [couchdb]
    uuid = couchdb-prod

    [vhosts]
    /api/v1/proxy/namespaces/database/services/couchdb:5984/ = /

    # # Admin user is configured using the Bootstrap Companion app
    # [admins]
    # admin = change-me

    [log]
    level = info
    # level = warning

    [couch_httpd_auth]
    require_valid_user = true
    secret = 16393A97-1FC3-4842-BCE6-DDF0EBF0AB9B
    timeout = 3600

    [native_query_servers]
    erlang = {couch_native_process, start_link, []}

    [httpd]
    # [default.ini] socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]
    socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}, {keepalive,true}]
    # [default.ini] server_options = [{backlog, 128}, {acceptor_pool_size, 16}]
    # server_options = [{backlog, 8192}, {acceptor_pool_size, 4096}]
    # allow_jsonp = true
    # enable_cors = true

    # [cors]
    # credentials = true
    # origins = *
    # headers = X-Couch-Id, X-Couch-Rev, Authorization, Content-Type
    # methods = GET,POST,PUT,DELETE,HEAD,OPTIONS

    [replicator]
    ; worker_batch_size = 1000
    worker_batch_size = 4096
    max_replication_retry_count = infinity

    [cluster]
    # q=8   ; Shards
    # n=3   ; Replicas: The number of copies there is of every document. (n=1 all node up,n=2 any one node down,...)
    # r=2   ; The number of copies of a document with the same revision that have to be read before CouchDB returns with a 200 and the document
    # w=2   ; The number of nodes that need to save a document before a write is returned with 201.
    # # curl http://localhost:5986/nodes -d '{"zone":"us-east-1"}'
    # # placement = us-east-1:2,us-west-1:1
    q=8
    n=3
    r=2
    w=2

    [chttpd]
    # [default.ini] backlog = 512
    backlog = 8192
    # [default.ini] socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}]
    socket_options = [{recbuf, 262144}, {sndbuf, 262144}, {nodelay, true}, {keepalive,true}]
